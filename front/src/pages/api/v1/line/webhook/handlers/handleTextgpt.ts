import type { DialogflowContext } from "@/types/models";
import {
  Message,
  TextEventMessage,
  TextMessage,
  EventSource,
  StickerMessage,
} from "@line/bot-sdk/lib/types";
import { lineClient } from "@/pages/api/v1/line/libs";
import { Configuration, OpenAIApi } from "openai";

/**
 * LINE botã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ã‘å–ã£ãŸã¨ãã®å‡¦ç†
 */
const handleTextgpt = async (
  message: TextEventMessage,
  contexts: DialogflowContext[],
  replyToken: string,
  source: EventSource
) => {
  /**
   * LINE botã‹ã‚‰è¿”ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—
   */
  let replyMessage: Message[] = [
    {
      type: "text",
      text: "ã™ã¿ã¾ã›ã‚“ï¼Œã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸğŸ¤”",
    },
  ];
  console.log(replyMessage);

  // gptã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆ
  const apiKey = process.env.OPENAI_API_KEY;
  const configuration = new Configuration({
    apiKey: apiKey,
  });
  const openai = new OpenAIApi(configuration);
  try {
    const response = await openai.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages: [{ role: "assistant", content: message.text }],
    });

    if (response.data.choices && response.data.choices.length > 0) {
      if (response.data.choices[0].message){
        const res = response.data.choices[0].message.content;
        replyMessage = [
          {
            type: "text",
            text: res,
          } as TextMessage,
        ];
      }
    }
  } catch (error) {
    console.error("GPTã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼:", error);
  }

  /**
   * LINE botã‹ã‚‰è¿”ä¿¡ã—ãŸçµæœ
   */
  const messageAPIResponse = await lineClient.replyMessage(
    replyToken,
    replyMessage
  );

  return { messageAPIResponse };
};

export default handleTextgpt;
